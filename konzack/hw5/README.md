# Questions answers for day 5
1. Having three evaluation metrics makes it harder to quickly chose between different algorithms.
A: a) True

2. Which model to chose given certain criteria?
A: d)

3. Which statement is true?
A: a) Accuracy is an optimizing metric, running time and memory are satisficing metrics

4. Which train/dev/test split to use?
A: b) 9.5M/250/250
- the test and evaluation tests are sufficiently large in given the big data set so they do not have to get any larger

5. You should not add training data from a different distribution to your existing data.
A: b) False
- the data might decrease the performance on the dev and test set
- however, the quality of the evaluation itself is not affected by modifications on the training set alone

6. Why do you object to adding the data to the test set?
A: a), b) and c)

7. d)s

8. How to define human level performance?
A: b)

9. a)

10. c)

11. d) b)

12. b) d)

13. c)

14. d)

15. a) b) d)
